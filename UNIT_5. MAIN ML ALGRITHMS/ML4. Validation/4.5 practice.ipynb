{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем значение ошибки для случайно предсказанных классов. Нашим алгоритмом будет монетка с тремя гранями, которая пытается угадать класс ириса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "iris_data = pd.read_csv('./data/iris.data', \n",
    "                        names=['sepal_length', 'sepal_width', \n",
    "                               'petal_length', 'petal_width', 'class'])\n",
    "\n",
    "# Функция, выбирающая один класс из заданного кол-ва классов\n",
    "def monetka(n_classes=3):\n",
    "    classes = np.arange(n_classes)\n",
    "    predicted = np.random.choice(classes)\n",
    "    \n",
    "    return predicted\n",
    "\n",
    "# Определить количество примеров, классов и сформировать словарь для конвертирования имени класса в порядковое число\n",
    "n = iris_data.shape[0]\n",
    "class_to_num = {cl: num for num, cl in enumerate(np.unique(iris_data['class']))}\n",
    "n_classes = len(class_to_num)\n",
    "\n",
    "# Истинные значения\n",
    "y = np.array(iris_data['class'].apply(lambda cl: class_to_num[cl]))\n",
    "\n",
    "# Предсказанные монеткой значения\n",
    "y_pred = np.array([monetka(n_classes) for _ in range(n)])\n",
    "y_hat = np.zeros((n, n_classes), dtype=np.float32)\n",
    "for num in class_to_num.values():\n",
    "    y_hat[:, num] = 1. * (y_pred == num)\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Посчитаем значение ошибки\n",
    "log_loss(y, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для более понятных человеку результатов рассмотрим класс популярных метрик, относящихся к бинарной классификации. Для подсчёта метрик возьмём искусственную задачу, где определим истинные классы следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100    # размер выборки\n",
    "p = 0.1    # доля примеров класса 1\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# Сгенерируем n примеров с долей единиц равной p\n",
    "dist = stats.bernoulli(p)\n",
    "y_true = dist.rvs(n)\n",
    "print(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(y_true, y_pred):\n",
    "    P = np.sum(y_true == 1)\n",
    "    N = np.sum(y_true == 0)\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "\n",
    "    acc = (TP + TN) / (P + N)\n",
    "    \n",
    "    return acc, TP, TN, P, N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "проблема accuracy: если выборка содержит разное количество примеров каждого класса, то добиться высокой точности можно без предсказывания редких классов.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дисбаланс классов можно избежать с помощью метрик precision, recall и F1-score. Посчитаем метрики precision и recall для нашей задачи с помощью методов precision_score и recall_score библиотеки sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision = precision_score(y_true, 1 - y_pred)\n",
    "recall = recall_score(y_true, 1 - y_pred)\n",
    "print('precision: {:.2f}\\nrecall: {:.2f}'.format(precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "print('F1-score: {:.2f}'.format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем precision-recall curve, используя метод precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precisions, recalls, _ = precision_recall_curve(y_true, y_pred)\n",
    "\n",
    "plt.step(recalls, precisions, color='b', alpha=0.2, where='post')\n",
    "plt.fill_between(recalls, precisions, step='post', alpha=0.2, color='b')\n",
    "plt.xlabel('Recall');\n",
    "plt.ylabel('Precision');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix. Это матрица, которая предсказывает отношений истинных и предсказанных значений. Вернёмся к задаче с ирисами и посчитаем confusion matrix с помощью метода confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Определить количество примеров, классов и сформировать словарь для конвертирования имени класса в порядковое число\n",
    "n = iris_data.shape[0]\n",
    "class_to_num = {cl: num for num, cl in enumerate(np.unique(iris_data['class']))}\n",
    "n_classes = len(class_to_num)\n",
    "\n",
    "# Истинные значения\n",
    "y_true = np.array(iris_data['class'].apply(lambda cl: class_to_num[cl]))\n",
    "\n",
    "# Предсказанные монеткой значения\n",
    "y_pred = np.array([monetka(n_classes) for _ in range(n)])\n",
    "\n",
    "conf_mat = confusion_matrix(y_true, y_pred).T\n",
    "print('Confusion matrix:\\n{}'.format(conf_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score \n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score \n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666665"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = 0.75\n",
    "recall = 0.6\n",
    "F1 = 2 * (precision * recall) / (precision + recall)\n",
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666665"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [0, 0, 1, 1, 1, 1, 0, 1]\n",
    "y_pred = [0, 1, 0, 0, 1, 1, 0, 1]\n",
    "\n",
    "f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [0, 0, 1, 0, 0, 1, 0]\n",
    "y_pred = [1, 1, 1, 0, 1, 1, 0]\n",
    "\n",
    "precision_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [0, 0, 1, 0, 0, 1, 0]\n",
    "y_pred = [1, 1, 1, 0, 1, 1, 0]\n",
    "\n",
    "recall_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "voices = pd.read_csv('voiceDataSet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 21 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   meanfreq  3168 non-null   float64\n",
      " 1   sd        3168 non-null   float64\n",
      " 2   median    3168 non-null   float64\n",
      " 3   Q25       3168 non-null   float64\n",
      " 4   Q75       3168 non-null   float64\n",
      " 5   IQR       3168 non-null   float64\n",
      " 6   skew      3168 non-null   float64\n",
      " 7   kurt      3168 non-null   float64\n",
      " 8   sp.ent    3168 non-null   float64\n",
      " 9   sfm       3168 non-null   float64\n",
      " 10  mode      3168 non-null   float64\n",
      " 11  centroid  3168 non-null   float64\n",
      " 12  meanfun   3168 non-null   float64\n",
      " 13  minfun    3168 non-null   float64\n",
      " 14  maxfun    3168 non-null   float64\n",
      " 15  meandom   3168 non-null   float64\n",
      " 16  mindom    3168 non-null   float64\n",
      " 17  maxdom    3168 non-null   float64\n",
      " 18  dfrange   3168 non-null   float64\n",
      " 19  modindx   3168 non-null   float64\n",
      " 20  label     3168 non-null   object \n",
      "dtypes: float64(20), object(1)\n",
      "memory usage: 519.9+ KB\n"
     ]
    }
   ],
   "source": [
    "voices.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>0.131884</td>\n",
       "      <td>0.084734</td>\n",
       "      <td>0.153707</td>\n",
       "      <td>0.049285</td>\n",
       "      <td>0.201144</td>\n",
       "      <td>0.151859</td>\n",
       "      <td>1.762129</td>\n",
       "      <td>6.630383</td>\n",
       "      <td>0.962934</td>\n",
       "      <td>0.763182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131884</td>\n",
       "      <td>0.182790</td>\n",
       "      <td>0.083770</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.832899</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.210938</td>\n",
       "      <td>4.203125</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>0.116221</td>\n",
       "      <td>0.089221</td>\n",
       "      <td>0.076758</td>\n",
       "      <td>0.042718</td>\n",
       "      <td>0.204911</td>\n",
       "      <td>0.162193</td>\n",
       "      <td>0.693730</td>\n",
       "      <td>2.503954</td>\n",
       "      <td>0.960716</td>\n",
       "      <td>0.709570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116221</td>\n",
       "      <td>0.188980</td>\n",
       "      <td>0.034409</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.909856</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>3.679688</td>\n",
       "      <td>3.640625</td>\n",
       "      <td>0.277897</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>0.142056</td>\n",
       "      <td>0.095798</td>\n",
       "      <td>0.183731</td>\n",
       "      <td>0.033424</td>\n",
       "      <td>0.224360</td>\n",
       "      <td>0.190936</td>\n",
       "      <td>1.876502</td>\n",
       "      <td>6.604509</td>\n",
       "      <td>0.946854</td>\n",
       "      <td>0.654196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142056</td>\n",
       "      <td>0.209918</td>\n",
       "      <td>0.039506</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.494271</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.937500</td>\n",
       "      <td>2.929688</td>\n",
       "      <td>0.194759</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3166</th>\n",
       "      <td>0.143659</td>\n",
       "      <td>0.090628</td>\n",
       "      <td>0.184976</td>\n",
       "      <td>0.043508</td>\n",
       "      <td>0.219943</td>\n",
       "      <td>0.176435</td>\n",
       "      <td>1.591065</td>\n",
       "      <td>5.388298</td>\n",
       "      <td>0.950436</td>\n",
       "      <td>0.675470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143659</td>\n",
       "      <td>0.172375</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.791360</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>3.593750</td>\n",
       "      <td>3.585938</td>\n",
       "      <td>0.311002</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.092884</td>\n",
       "      <td>0.183044</td>\n",
       "      <td>0.070072</td>\n",
       "      <td>0.250827</td>\n",
       "      <td>0.180756</td>\n",
       "      <td>1.705029</td>\n",
       "      <td>5.769115</td>\n",
       "      <td>0.938829</td>\n",
       "      <td>0.601529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.185607</td>\n",
       "      <td>0.062257</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.227022</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3168 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0     0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1     0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2     0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3     0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4     0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "...        ...       ...       ...       ...       ...       ...        ...   \n",
       "3163  0.131884  0.084734  0.153707  0.049285  0.201144  0.151859   1.762129   \n",
       "3164  0.116221  0.089221  0.076758  0.042718  0.204911  0.162193   0.693730   \n",
       "3165  0.142056  0.095798  0.183731  0.033424  0.224360  0.190936   1.876502   \n",
       "3166  0.143659  0.090628  0.184976  0.043508  0.219943  0.176435   1.591065   \n",
       "3167  0.165509  0.092884  0.183044  0.070072  0.250827  0.180756   1.705029   \n",
       "\n",
       "             kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       "0      274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
       "1      634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
       "2     1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
       "3        4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
       "4        4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "3163     6.630383  0.962934  0.763182  ...  0.131884  0.182790  0.083770   \n",
       "3164     2.503954  0.960716  0.709570  ...  0.116221  0.188980  0.034409   \n",
       "3165     6.604509  0.946854  0.654196  ...  0.142056  0.209918  0.039506   \n",
       "3166     5.388298  0.950436  0.675470  ...  0.143659  0.172375  0.034483   \n",
       "3167     5.769115  0.938829  0.601529  ...  0.165509  0.185607  0.062257   \n",
       "\n",
       "        maxfun   meandom    mindom    maxdom   dfrange   modindx   label  \n",
       "0     0.275862  0.007812  0.007812  0.007812  0.000000  0.000000    male  \n",
       "1     0.250000  0.009014  0.007812  0.054688  0.046875  0.052632    male  \n",
       "2     0.271186  0.007990  0.007812  0.015625  0.007812  0.046512    male  \n",
       "3     0.250000  0.201497  0.007812  0.562500  0.554688  0.247119    male  \n",
       "4     0.266667  0.712812  0.007812  5.484375  5.476562  0.208274    male  \n",
       "...        ...       ...       ...       ...       ...       ...     ...  \n",
       "3163  0.262295  0.832899  0.007812  4.210938  4.203125  0.161929  female  \n",
       "3164  0.275862  0.909856  0.039062  3.679688  3.640625  0.277897  female  \n",
       "3165  0.275862  0.494271  0.007812  2.937500  2.929688  0.194759  female  \n",
       "3166  0.250000  0.791360  0.007812  3.593750  3.585938  0.311002  female  \n",
       "3167  0.271186  0.227022  0.007812  0.554688  0.546875  0.350000  female  \n",
       "\n",
       "[3168 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f80d2948890>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA20AAAI/CAYAAADkwzGCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAb60lEQVR4nO3df4zkd33f8de7XEIRl4KpYeWcnawrOVEg10K4IiTUdE+0/LIagxRaI0rshPaSFqJUvUq9pH+EgpBOaknUSDSNE6M4TZoLCSRYnNvUddhEkQLBpsjGtigXcsWHLSMwcjhAVEc+/WPH0nLZ8+3tzOy8d/bxkFY3853vd+azp4/m9nmf73y3xhgBAACgp7+26AEAAABwaaINAACgMdEGAADQmGgDAABoTLQBAAA0JtoAAAAaO7DoASTJ1VdfPVZXVxc9jD3jq1/9ap797GcvehgwE+Yzy8R8ZlmYyyyTvTKf77vvvi+OMZ6/1WMtom11dTX33nvvooexZ6yvr2dtbW3Rw4CZMJ9ZJuYzy8JcZpnslflcVf/3Uo85PRIAAKAx0QYAANCYaAMAAGhMtAEAADQm2gAAABoTbQAAAI2JNgAAgMZEGwAAQGOiDQAAoDHRBgAA0JhoAwAAaEy0AQAANCbaAAAAGhNtAAAAjYk2AACAxkQbAABAY6INAACgMdEGAADQmGgDAABoTLQBAAA0dtloq6rrquojVfVwVT1YVT812f6Oqvp8VX1y8vW6Tcf8dFWdqapPV9Wr5/kNAAAALLMD29jnQpLjY4xPVNV3JLmvqu6ePPbzY4z/uHnnqnphkpuTvCjJdyb5X1X1PWOMb85y4AAAAPvBZVfaxhiPjTE+Mbn9lSQPJzn0NIfclOTUGOMbY4w/T3ImyctmMVgAAID95oo+01ZVq0lekuRjk01vr6r7q+p9VXXVZNuhJI9sOuxcnj7yAAAAuIQaY2xvx6qDSf4wybvHGB+sqpUkX0wykrwryTVjjB+rqvcm+ZMxxq9Pjrs9yV1jjA9c9HzHkhxLkpWVlZeeOnVqVt/T0jt//nwOHjy46GHATJjPLBPzmUt54PNP7vjYw4eeM8ORbI+5zDLZK/P56NGj940xjmz12HY+05aq+rYkH0jyG2OMDybJGOPxTY//cpIPT+6eS3LdpsOvTfLoxc85xrgtyW1JcuTIkbG2tradoZBkfX09/r5YFuYzy8R85lJuPXF6x8eeffPa7AayTeYyy2QZ5vN2rh5ZSW5P8vAY4+c2bb9m025vSPKpye07k9xcVc+squuT3JDkT2c3ZAAAgP1jOyttr0jyliQPVNUnJ9t+JsmbqurF2Tg98mySH0+SMcaDVfX+JA9l48qTb3PlSAAAgJ25bLSNMf44SW3x0F1Pc8y7k7x7inEBAACQK7x6JAAAALtLtAEAADQm2gAAABoTbQAAAI2JNgAAgMZEGwAAQGOiDQAAoDHRBgAA0JhoAwAAaEy0AQAANCbaAAAAGhNtAAAAjR1Y9AAAALi01ROnd3zs2ZM3znAkwKJYaQMAAGhMtAEAADQm2gAAABoTbQAAAI2JNgAAgMZcPRIAYBumuYojwDSstAEAADQm2gAAABoTbQAAAI2JNgAAgMZEGwAAQGOiDQAAoDHRBgAA0JhoAwAAaEy0AQAANCbaAAAAGhNtAAAAjYk2AACAxkQbAABAY6INAACgMdEGAADQmGgDAABoTLQBAAA0JtoAAAAaE20AAACNiTYAAIDGRBsAAEBjog0AAKAx0QYAANCYaAMAAGhMtAEAADQm2gAAABoTbQAAAI2JNgAAgMZEGwAAQGOiDQAAoDHRBgAA0JhoAwAAaEy0AQAANCbaAAAAGhNtAAAAjYk2AACAxkQbAABAY6INAACgMdEGAADQmGgDAABoTLQBAAA0JtoAAAAaE20AAACNiTYAAIDGRBsAAEBjog0AAKAx0QYAANCYaAMAAGhMtAEAADQm2gAAABoTbQAAAI2JNgAAgMZEGwAAQGMHFj0AAIDdsHri9KKHALAjVtoAAAAaE20AAACNiTYAAIDGRBsAAEBjog0AAKAx0QYAANCYaAMAAGhMtAEAADQm2gAAABoTbQAAAI2JNgAAgMZEGwAAQGOiDQAAoDHRBgAA0JhoAwAAaEy0AQAANCbaAAAAGhNtAAAAjYk2AACAxkQbAABAY6INAACgMdEGAADQ2GWjraquq6qPVNXDVfVgVf3UZPvzquruqvrM5M+rJturqn6hqs5U1f1V9QPz/iYAAACW1XZW2i4kOT7G+L4kL0/ytqp6YZITSe4ZY9yQ5J7J/SR5bZIbJl/HkvzizEcNAACwT1w22sYYj40xPjG5/ZUkDyc5lOSmJHdMdrsjyesnt29K8mtjw0eTPLeqrpn5yAEAAPaBK/pMW1WtJnlJko8lWRljPJZshF2SF0x2O5TkkU2HnZtsAwAA4Aod2O6OVXUwyQeS/Ksxxl9U1SV33WLb2OL5jmXj9MmsrKxkfX19u0PZ986fP+/vi6VhPrNMzOfejh++sOgh7LqdzkdzmWWyDPN5W9FWVd+WjWD7jTHGByebH6+qa8YYj01Of/zCZPu5JNdtOvzaJI9e/JxjjNuS3JYkR44cGWtrazv7Dvah9fX1+PtiWZjPLBPzubdbT5xe9BB23dk3r+3oOHOZZbIM83k7V4+sJLcneXiM8XObHrozyS2T27ck+dCm7T8yuYrky5M8+dRplAAAAFyZ7ay0vSLJW5I8UFWfnGz7mSQnk7y/qt6a5HNJ3jh57K4kr0tyJsnXkvzoTEcMAACwj1w22sYYf5ytP6eWJK/cYv+R5G1TjgsAAIBc4dUjAQAA2F2iDQAAoDHRBgAA0JhoAwAAaEy0AQAANCbaAAAAGhNtAAAAjYk2AACAxkQbAABAY6INAACgMdEGAADQmGgDAABoTLQBAAA0JtoAAAAaE20AAACNiTYAAIDGRBsAAEBjog0AAKAx0QYAANCYaAMAAGhMtAEAADQm2gAAABo7sOgBAAAwH6snTu/ouOOHL+TWE6dz9uSNMx4RsBNW2gAAABoTbQAAAI2JNgAAgMZEGwAAQGOiDQAAoDHRBgAA0JhoAwAAaEy0AQAANCbaAAAAGhNtAAAAjYk2AACAxkQbAABAY6INAACgMdEGAADQmGgDAABoTLQBAAA0JtoAAAAaE20AAACNiTYAAIDGRBsAAEBjog0AAKAx0QYAANCYaAMAAGhMtAEAADQm2gAAABoTbQAAAI2JNgAAgMZEGwAAQGOiDQAAoDHRBgAA0JhoAwAAaEy0AQAANCbaAAAAGhNtAAAAjYk2AACAxkQbAABAY6INAACgMdEGAADQmGgDAABoTLQBAAA0JtoAAAAaE20AAACNiTYAAIDGRBsAAEBjog0AAKAx0QYAANCYaAMAAGhMtAEAADQm2gAAABoTbQAAAI2JNgAAgMZEGwAAQGOiDQAAoDHRBgAA0NiBRQ8AAGC7Vk+cXvQQAHadlTYAAIDGRBsAAEBjog0AAKAx0QYAANCYaAMAAGhMtAEAADQm2gAAABoTbQAAAI2JNgAAgMZEGwAAQGOiDQAAoDHRBgAA0JhoAwAAaEy0AQAANCbaAAAAGhNtAAAAjV022qrqfVX1har61KZt76iqz1fVJydfr9v02E9X1Zmq+nRVvXpeAwcAANgPtrPS9qtJXrPF9p8fY7x48nVXklTVC5PcnORFk2P+c1U9Y1aDBQAA2G8uG21jjD9K8sQ2n++mJKfGGN8YY/x5kjNJXjbF+AAAAPa1aT7T9vaqun9y+uRVk22HkjyyaZ9zk20AAADsQI0xLr9T1WqSD48xvn9yfyXJF5OMJO9Kcs0Y48eq6r1J/mSM8euT/W5PctcY4wNbPOexJMeSZGVl5aWnTp2ayTe0H5w/fz4HDx5c9DBgJsxnlon5PH8PfP7JRQ9hX1h5VvL415PDh56z6KHA1PbKe/PRo0fvG2Mc2eqxAzt5wjHG40/drqpfTvLhyd1zSa7btOu1SR69xHPcluS2JDly5MhYW1vbyVD2pfX19fj7YlmYzywT83n+bj1xetFD2BeOH76Q9zxwIGffvLboocDUluG9eUenR1bVNZvuviHJU1eWvDPJzVX1zKq6PskNSf50uiECAADsX5ddaauq30yyluTqqjqX5GeTrFXVi7NxeuTZJD+eJGOMB6vq/UkeSnIhydvGGN+cz9ABAACW32WjbYzxpi023/40+787ybunGRQAAAAbprl6JAAAAHMm2gAAABoTbQAAAI2JNgAAgMZEGwAAQGOiDQAAoDHRBgAA0JhoAwAAaEy0AQAANCbaAAAAGhNtAAAAjYk2AACAxkQbAABAY6INAACgMdEGAADQmGgDAABo7MCiBwAA7D2rJ07v+NizJ2+c4UgAlp+VNgAAgMZEGwAAQGOiDQAAoDGfaQMAYEs+uwg9WGkDAABoTLQBAAA0JtoAAAAaE20AAACNiTYAAIDGRBsAAEBjog0AAKAx0QYAANCYaAMAAGhMtAEAADQm2gAAABoTbQAAAI2JNgAAgMZEGwAAQGOiDQAAoDHRBgAA0JhoAwAAaEy0AQAANCbaAAAAGhNtAAAAjYk2AACAxkQbAABAY6INAACgMdEGAADQmGgDAABoTLQBAAA0dmDRAwAAFmP1xOlFDwGAbbDSBgAA0JiVNgBgV1nhA7gyVtoAAAAas9IGAHuUFSuA/cFKGwAAQGOiDQAAoDHRBgAA0JhoAwAAaEy0AQAANCbaAAAAGhNtAAAAjYk2AACAxkQbAABAY6INAACgMdEGAADQmGgDAABoTLQBAAA0JtoAAAAaE20AAACNiTYAAIDGRBsAAEBjog0AAKAx0QYAANCYaAMAAGhMtAEAADQm2gAAABoTbQAAAI2JNgAAgMZEGwAAQGOiDQAAoDHRBgAA0JhoAwAAaEy0AQAANCbaAAAAGjuw6AEAALB8Vk+c3vGxZ0/eOMORwN5npQ0AAKAx0QYAANCYaAMAAGhMtAEAADQm2gAAABpz9UgAWKBprrAHy8qVJ+FbWWkDAABoTLQBAAA0JtoAAAAaE20AAACNiTYAAIDGRBsAAEBjl422qnpfVX2hqj61advzquruqvrM5M+rJturqn6hqs5U1f1V9QPzHDwAAMCy285K268mec1F204kuWeMcUOSeyb3k+S1SW6YfB1L8ouzGSYAAMD+dNloG2P8UZInLtp8U5I7JrfvSPL6Tdt/bWz4aJLnVtU1sxosAADAfrPTz7StjDEeS5LJny+YbD+U5JFN+52bbAMAAGAHDsz4+WqLbWPLHauOZeMUyqysrGR9fX3GQ1le58+f9/fF0jCfWSY7mc/HD1+Yz2BgCivP2rtz078pXGwZftbYabQ9XlXXjDEem5z++IXJ9nNJrtu037VJHt3qCcYYtyW5LUmOHDky1tbWdjiU/Wd9fT3+vlgW5jPLZCfz+dYTp+czGJjC8cMX8p4HZv1/+7vj7JvXFj0EmlmGnzV2enrknUlumdy+JcmHNm3/kclVJF+e5MmnTqMEAADgyl32v1Cq6jeTrCW5uqrOJfnZJCeTvL+q3prkc0neONn9riSvS3ImydeS/OgcxgwAALBvXDbaxhhvusRDr9xi35HkbdMOCgAAgA07PT0SAACAXSDaAAAAGhNtAAAAjYk2AACAxkQbAABAY6INAACgMdEGAADQmGgDAABoTLQBAAA0JtoAAAAaE20AAACNHVj0AABgr1s9cTpJcvzwhdw6uQ0As2KlDQAAoDHRBgAA0JhoAwAAaEy0AQAANCbaAAAAGhNtAAAAjYk2AACAxkQbAABAY6INAACgMdEGAADQmGgDAABoTLQBAAA0JtoAAAAaE20AAACNiTYAAIDGRBsAAEBjog0AAKAx0QYAANCYaAMAAGhMtAEAADQm2gAAABoTbQAAAI2JNgAAgMZEGwAAQGOiDQAAoDHRBgAA0JhoAwAAaEy0AQAANCbaAAAAGhNtAAAAjYk2AACAxkQbAABAY6INAACgMdEGAADQmGgDAABoTLQBAAA0JtoAAAAaE20AAACNiTYAAIDGRBsAAEBjog0AAKAx0QYAANCYaAMAAGhMtAEAADQm2gAAABoTbQAAAI2JNgAAgMZEGwAAQGOiDQAAoDHRBgAA0JhoAwAAaOzAogcAAAAdrJ44PdXxZ0/eOKORwLey0gYAANCYaAMAAGhMtAEAADTmM20AACyNaT+XBh1ZaQMAAGhMtAEAADQm2gAAABoTbQAAAI2JNgAAgMZEGwAAQGOiDQAAoDG/pw2ApTDt72Y6e/LGGY0EAGbLShsAAEBjog0AAKAxp0cCAMAeNs3p4U4N3xustAEAADQm2gAAABoTbQAAAI2JNgAAgMZEGwAAQGOuHgkAmf6XcwPAvFhpAwAAaEy0AQAANCbaAAAAGvOZNgAAmAGfjWVerLQBAAA0JtoAAAAaE20AAACN+UwbAADsU9N8Du/syRtnOBKejpU2AACAxqZaaauqs0m+kuSbSS6MMY5U1fOS/FaS1SRnk/zjMcaXpxsmAADA/jSLlbajY4wXjzGOTO6fSHLPGOOGJPdM7gMAALAD8/hM201J1ia370iynuTfzuF1AGjI5yMAYLamXWkbSf5nVd1XVccm21bGGI8lyeTPF0z5GgAAAPtWjTF2fnDVd44xHq2qFyS5O8lPJrlzjPHcTft8eYxx1RbHHktyLElWVlZeeurUqR2PY785f/58Dh48uOhhwEyYz8vngc8/ueNjDx96zkJed1ZWnpU8/vVFjwKmZy6zHdO8Z++mvfKzxtGjR+/b9JGzbzFVtH3LE1W9I8n5JP88ydoY47GquibJ+hjje5/u2CNHjox77713JuPYD9bX17O2trboYcBMmM/LZ1GnR07zurNy/PCFvOcBv02Hvc9cZjv2yinte+Vnjaq6ZLTt+PTIqnp2VX3HU7eTvCrJp5LcmeSWyW63JPnQTl8DAABgv5vmv1BWkvxuVT31PP9tjPE/qurjSd5fVW9N8rkkb5x+mAAAAPvTjqNtjPHZJH9ni+1fSvLKaQYFAADAhln8njYAAADmxCdMAWijw8VEAKAbK20AAACNiTYAAIDGRBsAAEBjog0AAKAx0QYAANCYaAMAAGhMtAEAADQm2gAAABoTbQAAAI2JNgAAgMZEGwAAQGOiDQAAoDHRBgAA0JhoAwAAaOzAogcAQD+rJ04veggAwISVNgAAgMZEGwAAQGOiDQAAoDHRBgAA0JhoAwAAaEy0AQAANCbaAAAAGhNtAAAAjYk2AACAxkQbAABAY6INAACgMdEGAADQmGgDAABoTLQBAAA0JtoAAAAaE20AAACNiTYAAIDGRBsAAEBjog0AAKAx0QYAANCYaAMAAGhMtAEAADQm2gAAABoTbQAAAI2JNgAAgMZEGwAAQGMHFj0AgGW2euL0jo89e/LGGY4EANirrLQBAAA0ZqUNYElNs8oHAPRhpQ0AAKAxK20ATVkpA6Czaf+d8tnt7bPSBgAA0JhoAwAAaEy0AQAANOYzbQCX4bNlAMAiWWkDAABoTLQBAAA0JtoAAAAaE20AAACNiTYAAIDGRBsAAEBjog0AAKAxv6cN2Bf8rjUAYK+y0gYAANCYaAMAAGhMtAEAADQm2gAAABoTbQAAAI2JNgAAgMZEGwAAQGOiDQAAoDHRBgAA0JhoAwAAaEy0AQAANCbaAAAAGhNtAAAAjYk2AACAxkQbAABAY6INAACgMdEGAADQmGgDAABoTLQBAAA0JtoAAAAaO7DoAQC7b/XE6YW87tmTNy7kdQEA9jIrbQAAAI1ZaQN2zVYrfMcPX8it21z5s1IHAOxHVtoAAAAas9IGCzLt58r246rToj6LBwCwSFbaAAAAGhNtAAAAjYk2AACAxkQbAABAY6INAACgMdEGAADQmEv+AwAAu26aX+Wz3371kZU2AACAxqy0se/5hc0AAHvLlfz8dvzwhdy6af+9uEpnpQ0AAKCxua20VdVrkvynJM9I8itjjJPzei1mx7nFe4cVQgCA/WEuK21V9Ywk703y2iQvTPKmqnrhPF4LAABgmc1rpe1lSc6MMT6bJFV1KslNSR6a0+vNxSJXnZ7utS8+L3fWr71Ti1z5scoHAMCymtdn2g4leWTT/XOTbQAAAFyBGmPM/kmr3pjk1WOMfza5/5YkLxtj/OSmfY4lOTa5+71JPj3zgSyvq5N8cdGDgBkxn1km5jPLwlxmmeyV+fzdY4znb/XAvE6PPJfkuk33r03y6OYdxhi3JbltTq+/1Krq3jHGkUWPA2bBfGaZmM8sC3OZZbIM83lep0d+PMkNVXV9VX17kpuT3Dmn1wIAAFhac1lpG2NcqKq3J/n9bFzy/31jjAfn8VoAAADLbG6/p22McVeSu+b1/Puc00pZJuYzy8R8ZlmYyyyTPT+f53IhEgAAAGZjXp9pAwAAYAZEWzNV9Zqq+nRVnamqE1s8/syq+q3J4x+rqtXJ9tWq+npVfXLy9V92e+xwsW3M5x+sqk9U1YWq+uGLHrulqj4z+bpl90YNf9WUc/mbm96bXZSLhdvGfP7XVfVQVd1fVfdU1Xdvesx7M61MOZ/3zPuz0yMbqapnJPk/Sf5hNn5twseTvGmM8dCmff5lkr89xviJqro5yRvGGP9kEm8fHmN8/+6PHP6qbc7n1SR/I8m/SXLnGON3Jtufl+TeJEeSjCT3JXnpGOPLu/gtQJLp5vLksfNjjIO7OWa4lG3O56NJPjbG+FpV/Yska5OfNbw308o083ny2J55f7bS1svLkpwZY3x2jPH/kpxKctNF+9yU5I7J7d9J8sqqql0cI2zXZefzGOPsGOP+JH950bGvTnL3GOOJyQ8Ddyd5zW4MGrYwzVyGbrYznz8yxvja5O5Hs/H7dhPvzfQzzXzeU0RbL4eSPLLp/rnJti33GWNcSPJkkr85eez6qvrfVfWHVfX35j1YuIztzOd5HAuzNu18/OtVdW9VfbSqXj/bocEVu9L5/NYk/32Hx8K8TTOfkz30/jy3S/6zI1utmF18/uql9nksyXeNMb5UVS9N8ntV9aIxxl/MepCwTduZz/M4FmZt2vn4XWOMR6vqbyX5g6p6YIzxZzMaG1ypbc/nqvqn2TgV8u9f6bGwS6aZz8keen+20tbLuSTXbbp/bZJHL7VPVR1I8pwkT4wxvjHG+FKSjDHuS/JnSb5n7iOGS9vOfJ7HsTBrU83HMcajkz8/m2Q9yUtmOTi4Qtuaz1X1D5L8uyQ/NMb4xpUcC7tomvm8p96fRVsvH09yQ1VdX1XfnuTmJBdfyebOJE9dremHk/zBGGNU1fMnH8bM5H8Lbkjy2V0aN2xlO/P5Un4/yauq6qqquirJqybbYBF2PJcnc/iZk9tXJ3lFkoee/iiYq8vO56p6SZJfysYPuF/Y9JD3ZrrZ8Xzea+/PTo9sZIxxoareno03wGcked8Y48GqemeSe8cYdya5Pcl/raozSZ7IxuRMkh9M8s6qupDkm0l+YozxxO5/F7BhO/O5qv5ukt9NclWSf1RV/36M8aIxxhNV9a5svBknyTvNZxZlmrmc5PuS/FJV/WU2/qP05OarmsFu2+bPGv8hycEkvz251tnnxhg/5L2ZbqaZz9lj788u+Q8AANCY0yMBAAAaE20AAACNiTYAAIDGRBsAAEBjog0AAKAx0QYAANCYaAMAAGhMtAEAADT2/wFp+gJ6uOlinQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "voices['meanfreq'].hist(figsize=(15, 10), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
